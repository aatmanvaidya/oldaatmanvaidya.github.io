---
---

@string{aaai = {Association for the Advancement of Artificial Intelligence,}}
@string{acm = {Association for Computing Machinery,}}
@string{arxiv = {arXiv,}}
@string{acl = {Association for Computational Linguistics,}}

% all the fileds - abbr, title, preview (conf image), author, abstract, booktitle, year, publisher, pdf, metatype, html, url, doi, selected, poster, slides, award, dataset.
% see the _layouts/bib.html file for all the types 

@inproceedings{arora2023uli,
  abbr={NAACL 2024},
  title={The Uli Dataset: An Exercise in Experience Led Annotation of oGBV},
  author={Arora, Arnav and Jinadoss, Maha and Arora, Cheshta and George, Denny and Brindaalakshmi and .... and Vaidya, Aatman and Prabhakar, Tarunima},
  abstract={Online gender-based violence has grown concomitantly with the adoption of the internet and social media. Its effects are worse in the Global majority where many users use social media in languages other than English. The scale and volume of conversations on the internet have necessitated the need for automated detection of hate speech and, more specifically, gendered abuse. There is, however, a lack of language-specific and contextual data to build such automated tools. In this paper, we present a dataset on gendered abuse in three languages- Hindi, Tamil and Indian English. The dataset comprises of tweets annotated along three questions pertaining to the experience of gender abuse, by experts who identify as women or a member of the LGBTQIA+ community in South Asia. Through this dataset, we demonstrate a participatory approach to creating datasets that drive AI systems.},
  booktitle={The 8th Workshop on Online Abuse and Harms at Annual Conference of the North American Chapter of the Association for Computational Linguistics},
  year={2024},
  publisher={@acl},
  html={https://aclanthology.org/2024.woah-1.16/},
  pdf={../papers/ogbv_dataset.pdf},
  award={Outstanding Paper Award},
  dataset={https://github.com/tattle-made/uli_dataset},
  website={https://uli.tattle.co.in/},
  metatype={published}
}

@inproceedings{vaidya2024analysing,
  abbr={CODS-COMAD},
  title={Analysing the Spread of Toxicity on Twitter},
  author={Vaidya, Aatman and Nagar, Seema and Nanavati, Amit A},
  abstract={The spread of hate speech on social media platforms has become a rising concern in recent years. Understanding the spread of hate is crucial for mitigating its harmful effects and fostering a healthier online environment. In this paper, we propose a new model to capture the evolution of toxicity in a network -- if a tweet with a certain toxicity (hatefulness) is posted, how much toxic a social network will become after a given number of rounds. We compute a toxicity score for each tweet, indicating the extent of the hatefulness of that tweet. Toxicity spread has not been adequately addressed in the existing literature. The two popular paradigms for modelling information spread, namely the Susceptible-Infected-Recovered (SIR) and its variants, as well as the spreading-activation models (SPA), are not suitable for modelling toxicity spread. The first paradigm employs a threshold and categorizes tweets as either toxic or non-toxic, while the second paradigm treats hate as energy and applies energy-conversion principles to model its propagation. Through analysis of a Twitter dataset consisting of $19.58$ million tweets, we observe that the total toxicity, as well as the average toxicity of original tweets and retweets in the network, does not remain constant but rather increases over time. In this paper, we propose a new method for toxicity spread. First, we categorize users into three distinct groups: Amplifiers, Attenuators, and Copycats. These categories are assigned based on the exchange of toxicity by a user, with Amplifiers sending out more toxicity than they receive, Attenuators experiencing a higher influx of toxicity compared to what they generate, and Copycats simply mirroring the hate they receive. We perform extensive experimentation on Barabási–Albert (BA) graphs, as well as subgraphs extracted from the Twitter dataset. Our model is able to replicate the patterns of toxicity.},
  booktitle={Proceedings of the 7th Joint International Conference on Data Science \& Management of Data (11th ACM IKDD CODS and 29th COMAD)},
  year={2024},
  pages={118--126},
  publisher={@acm},
  html={https://dl.acm.org/doi/10.1145/3632410.3632436},
  metatype={published}
}

@article{vaidya2024overview,
  abbr={ICON 2023},
  title={Overview of the 2023 ICON Shared Task on Gendered Abuse Detection in Indic Languages},
  author={Vaidya, Aatman and Arora, Arnav and Joshi, Aditya and Prabhakar, Tarunima},
  abstract={This paper reports the findings of the ICON 2023 on Gendered Abuse Detection in Indic Languages. The shared task deals with the detection of gendered abuse in online text. The shared task was conducted as a part of ICON 2023, based on a novel dataset in Hindi, Tamil and the Indian dialect of English. The participants were given three subtasks with the train dataset consisting of approximately 6500 posts sourced from Twitter. For the test set, approximately 1200 posts were provided. The shared task received a total of 9 registrations. The best F-1 scores are 0.616 for subtask 1, 0.572 for subtask 2 and, 0.616 and 0.582 for subtask 3. The paper contains examples of hateful content owing to its topic.},
  journal={The 20th International Conference on Natural Language Processing},
  year={2023},
  html={https://arxiv.org/abs/2401.03677},
  metatype={published},
  website={https://sites.google.com/view/icon2023-tattle-sharedtask/home}
}

@inproceedings{vaidya2023forecasting,
  abbr={CoGMI 2023},
  title={Forecasting the Spread of Toxicity on Twitter},
  author={Vaidya, Aatman and Nagar, Seema and Nanavati, Amit A},
  abstract={In this paper, we explore the question of whether it is possible to forecast the spread of hate on Twitter. Unlike most prior work which models the spread of Twitter over a network with the goal of predicting the future ``state" of a user (typically, as being "hateful" or not), here we are interested in how "hateful" (or toxic) the network as a whole becomes. We pose toxicity spread as a forecasting problem, and use ARIMA to find out whether the spread is forecastable. We find that toxicity spread is indeed forecasted by ARIMA. Given that it is forecastable, we ask two follow-up questions: (a) How well can we forecast it? and (b) What role, if any, does the structure of the retweet network play in forecasting? In order to answer these questions, we employ several techniques including Spatio-Temporal Graph Convolution Network (STGCN) and several variants of transformers. To determine the role that structure might play, we re-purpose the dataset in three ways: the network as a whole (the structure is ignored), communities interconnected with each other, and neighbourhoods of a set of individuals. Experiments with the network as a whole informs us how well we can forecast hate spread at a global level, while the latter experiments tell us whether and how network effects affect the forecasting. In an effort to tease out the effect of the network, we use two distinct techniques: STGCN, which requires the explicit connections in the form of a graph as input; and Transformers, where no explicit graph is given as input. Instead, we pose it as a multivariate analysis problem. We find that the PatchTST transformer performs the best at all levels. STGCN performs better than ARIMA suggesting that network structure matters. Somewhat interestingly, STGCN does not perform as well as PatchTST, suggesting that (a) PatchTST is able to implicitly learn the associations (flow of influence), and (b) the presence of explicit connections may not always imply influence.},
  booktitle={IEEE 5th International Conference on Cognitive Machine Intelligence (CogMI)},
  year={2023},
  html={https://ieeexplore.ieee.org/document/10431536},
  metatype={published},
}

@article{pandit2022coping,
  abbr={JPR},
  title={Coping resources of young people experiencing COVID-19 second wave, in India: a preliminary study},
  author={Pandit, Shilpa Ashok and Vaidya, Aatman and Shah, Aangi and Shah, Eshva and Iyer, Isha and Golani, Jhalak and Pishe, Kirti and Guliwala, Mantasha and Maheshwari, Shrishti and Dave, Tanishqua},
  abstract={The purpose of the student-led research study was to understand the experiences of COVID-19 in the second wave in terms of mental health and coping with loss and grief. To address the research questions, an exploratory survey tool was constructed, which documented the physiological and psychological experiences specific to anxiety, grief, panic, and distress through semi-structured schedules converted into google forms. The students were guided to construct the semi-structured questionnaire and the tool was translated and back-translated into regional languages of Gujarati, Marathi, Hindi, Malayalam, and Tamil. Given the lockdown, the data collection was carried out through telephonic and online interviews. Data collection was limited primarily to a youth population due to digital access being most available to youth (overall n = 203). Three key results are discussed. Firstly, data shows that the youth sample showed a clear preference for action readiness, even in the light of fear and distress due to the COVID-19 second wave. Females seemed to prefer a problem-solving coping pattern, but overall, the sample preferred to look at 'what they could do' in light of the fear and other distressing emotions. Second, given the age profile, the data showed that 50% of the sampled participants experienced moderate negative affect; 26% experienced low negative affect. Around 24% reported high negative affect in the aftermath of the COVID-19 second wave in May-July 2021. Third, data showed that participants reported two emotion focused coping strategies-through sharing more with the families and finding courage together. The coping strategies varied slightly according to the level of negative affect experienced. Given that the Government of India, in 2022, has initiated a telemental health program, with NIMHANS as a nodal agency, implications for policy and future research for mental health interventions leveraging technology are discussed.},
  booktitle={Journal of Psychosocial Research},
  year={2022},
  html={https://www.proquest.com/docview/2682863999?fromopenview=true&pq-origsite=gscholar},
  metatype={other}
}